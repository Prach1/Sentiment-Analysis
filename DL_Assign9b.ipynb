{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign9b.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prach1/CS69002_9A_18CS60R30/blob/master/DL_Assign9b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "67uywKsdnYcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmtGWpVsobkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6cb2cc21-54c5-4997-fcce-a125e7154540"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LYZcQMGeogWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "46b723bc-60da-4919-e334-f4f8244c4244"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Train_20K.csv', sep='\\t')\n",
        "print(df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  John Waters has given us a genuinely enjoyable...      1\n",
            "1  This first two seasons of this comedy series w...      1\n",
            "2  What an unfortunate mess is \"Shiner.\" I wanted...      0\n",
            "3  I'm not entirely sure Rob Schmidt qualifies as...      1\n",
            "4  i wasn't sure whether to laugh or cry. Porrett...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R110JOOgopys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "79a9b6e8-d76e-42cb-9901-b217bef05e1f"
      },
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Test_5K.csv', sep='\\t')\n",
        "print(df1.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  as always this is an inaccurate picture of the...      0\n",
            "1  Did the movie-makers even preview this before ...      0\n",
            "2  Heavily re-edited and often confusing, the ori...      0\n",
            "3  I notice that most of the people who think thi...      0\n",
            "4  First of all, this is a low-budget movie, so m...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hnZ5jHXuotFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "print(type(text_labels))\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "#print(type(text_reviews))\n",
        "#print(text_reviews[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hD13yhLoxud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_test_reviews = df1['text'].astype(str).tolist()\n",
        "text_test_labels = df1['label'].astype(int)\n",
        "#print(type(text_labels))\n",
        "\n",
        "text_test_reviews = [x.lower() for x in text_test_reviews]\n",
        "#print(type(text_reviews))\n",
        "#print(text_reviews[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TU8BkvVHo0V_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess(text):    \n",
        "  text = re.sub(r'<br.*?>',' ',text)\n",
        "  text = re.sub(r'[^\\w\\s]',' ',text) \n",
        "  text = re.sub(r'[0-9]+', ' ', text)\n",
        "  \n",
        "  return text\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WsznSUoVo2i8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "train_data = []\n",
        "train_data_X = []\n",
        "stop = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for review in text_reviews:\n",
        "  new_review = preprocess(review)\n",
        "  train_data.append(new_review)\n",
        "  \n",
        "print(train_data[0])\n",
        "\n",
        "for review in train_data:\n",
        "  review = [lemmatizer.lemmatize(word) for word in review.split() if word not in stop and word != '' and len(lemmatizer.lemmatize(word)) > 1]\n",
        "  train_data_X.append(review)\n",
        "  \n",
        "print(train_data_X[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1hXhtd8o430",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "test_data = []\n",
        "test_data_X = []\n",
        "stop = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for review in text_test_reviews:\n",
        "  new_review = preprocess(review)\n",
        "  test_data.append(new_review)\n",
        "  \n",
        "print(test_data[0])\n",
        "\n",
        "for review in test_data:\n",
        "  review = [lemmatizer.lemmatize(word) for word in review.split() if word not in stop and word != '' and len(lemmatizer.lemmatize(word)) > 1]\n",
        "  test_data_X.append(review)\n",
        "  \n",
        "print(test_data_X[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-pwTrf0o7oJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_frequency(dataset):\n",
        "  word_to_frequency = {}\n",
        " \n",
        "  for sent in dataset:\n",
        "    for word in sent:\n",
        "      if word not in word_to_frequency:\n",
        "        word_to_frequency[word] = 1\n",
        "      else:\n",
        "        word_to_frequency[word] += 1\n",
        "              \n",
        "  return word_to_frequency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3U_oesfBo93x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "  word_to_ix = {}\n",
        " \n",
        "  for word in dataset:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "              \n",
        "  word_to_ix['UNKNOWN'] = len(word_to_ix) \n",
        "              \n",
        "  return word_to_ix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l64UH7yApAUB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_frequency = generate_word_frequency(train_data_X + test_data_X)\n",
        "# for key in word_to_bigram_frequency:\n",
        "#   print(key)\n",
        "#   break\n",
        "\n",
        "new_word_dataset = []\n",
        "\n",
        "for word in word_to_frequency:\n",
        "  if(word_to_frequency[word] >= 3):\n",
        "    new_word_dataset.append(word)\n",
        "        \n",
        "print(len(word_to_frequency))\n",
        "print(len(new_word_dataset))\n",
        "\n",
        "word_to_ix = generate_word_ids(new_word_dataset)\n",
        "\n",
        "print(len(word_to_ix))\n",
        "print(word_to_ix['UNKNOWN'])\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2b9k5WcVpCq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['UNKNOWN']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "# def make_target(label, label_to_ix):\n",
        "#     return torch.LongTensor([label_to_ix[label]])\n",
        "    #return torch.LongTensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A5aOcFMpGAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = []\n",
        "\n",
        "for review in train_data_X:\n",
        "  embedding = torch.autograd.Variable(make_bow_vector(review)).cuda()\n",
        "  train.append(embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPi3-_4gpITG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import pickle\n",
        "\n",
        "test = []\n",
        "for review in test_data_X:\n",
        "  embedding = torch.autograd.Variable(make_bow_vector(review)).cuda()\n",
        "  test.append(embedding)\n",
        "  \n",
        "# fp = open(\"test.pickle\",\"wb\")\n",
        "# pickle.dump(test, fp)\n",
        "# fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bvHk0M0pKaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data = []\n",
        "\n",
        "# for index,review in enumerate(train):\n",
        "#   data.append((review,text_labels[index]))\n",
        "  \n",
        "# print(data[0])\n",
        "\n",
        "#label_to_tensor = torch.LongTensor(text_labels)\n",
        "\n",
        "label_to_tensor = []\n",
        "\n",
        "#print(text_labels)\n",
        "text_labels1 = []\n",
        "\n",
        "for label in text_labels:\n",
        "  text_labels1.append([label])\n",
        "  \n",
        "\n",
        "#print(text_labels1)\n",
        "\n",
        "for label in text_labels1:\n",
        "  label_to_tensor.append(torch.tensor(label, dtype = torch.long))\n",
        "  #print(label_to_tensor)\n",
        "  \n",
        "#print(label_to_tensor)\n",
        "\n",
        "#for label in label_to_tensor:\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQa2Go3ApMuc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_to_test_tensor = []\n",
        "\n",
        "text_test_labels1 = []\n",
        "\n",
        "for label in text_test_labels:\n",
        "  text_test_labels1.append([label])\n",
        "\n",
        "for label in text_test_labels1:\n",
        "  label_to_test_tensor.append(torch.tensor(label, dtype = torch.long))\n",
        "  \n",
        "#print(label_to_test_tensor)\n",
        "# fp = open(\"test.pickle\",\"wb\")\n",
        "# pickle.dump(label_to_test_tensor, fp)\n",
        "# fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1PhlYmepO3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.device('cuda') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlfJ-35lpokn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMrMsWOApRQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.NLLLoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6mxHNJtpcOR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# the training loop\n",
        "for epoch in range(10):\n",
        "  start = time.time()\n",
        "  for index, instance in enumerate(train):\n",
        "    bow.zero_grad()\n",
        "    label = Variable(label_to_tensor[index]).cuda()       \n",
        "    probs = bow(instance).cuda() # forward pass\n",
        "    loss = loss_function(probs, label)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  end = time.time()  \n",
        "  print('epoch is: ' +str(epoch) + ' and loss is: ' +str(loss.data) + ' and time taken is: ' +str(end-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qri3-TY0peVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}